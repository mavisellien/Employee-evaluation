# -*- coding: utf-8 -*-
"""Employee evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jA5HpUOIzDd-2uZqIg72ewXHV11jvgSd

# Before We Begin ##

Run the code in the following two code cells to "mount" the Google Drive directory.

## Mount Google Drive
Create a new folder named *lab3* in your Google Drive. Download and save a copy of the Notebook *lab3_tasks.ipynb* and the CSV files (i.e. *adult.csv* and *y_pred.csv*) to your Google Drive folder *lab3*.
"""

from google.colab import drive
drive.mount("/content/drive")

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/drive/My Drive"

"""# Task 1: Data Loading and Pre-processing

## Pandas
[Pandas](https://pandas.pydata.org/) is an open-source library, which provides high-performance, fast, easy-to-use data structures, and data analysis tools for manipulating numeric data and time series. In Pandas, we can import data from various file formats like *JSON*, *SQL*, *Microsoft Excel*, etc.

### Pandas vs. Numpy
In previous labs, we practised Numpy a lot, while in this task, we used Pandas to load the data. So, what are the differences between Pandas and Numpy? And which one is preferable?

In general, the powerful tools of **Pandas** are **Data frame and Series**, whereas the powerful tool of **Numpy** is **Arrays**. The basic idea of choice between them is that:
- When we work on **tabular data**, we prefer the **Pandas** module.
- When we work on **numerical data**, we prefer the **Numpy** module.

Next, we will load the *csv*-format data by calling the *read_csv()* function of Pandas.
"""

import numpy as np # Importing for potential future use
import pandas as pd
data = pd.read_csv('Matris.csv', index_col=False)
data

"""From the above, we can see the content of the dataset. In total, 32561 samples contain 14 attributes and a final prediction goal attribute. This dataset targets to predict whether income exceeds $50K/yr based on census data. It is also known as the "Census Income" dataset."""

data.iloc[50]

data.iloc[14:15]
# iloc is a purely integer-location based indexing for selection by position,
# but in order to show the target row in a dataframe structure,
# better to use iloc[position:position+1] instead of iloc[position]

"""There are missing values in this dataset. An example is illustrated above. To remove NaN values in the dataframe, we replace them with the average value (taking the average to prevent the attribute with NaN value from being assigned a significant value that dominates the prediction)."""

for k in data.keys():
  if(type(data[k][0])==str):
    # ffill means forward fill that fill the NaN entry with the last seen items within the same attribute column (contrastively, bfill means backward fill)
    data[k].ffill(inplace=True)
  else:
    # here fill the NaN entry with the mean value of the attribute column
    data[k].fillna(data[k].mean(), inplace=True)
data.iloc[:-1]

"""## Task 1.1: Create the Vector Representation for Data
Within the 14 attributes, the attributes with text values need to be converted into int type to create the vector representation for each data sample **<font color="green">(a TODO here)</font>**.

Hint: You may use scikit-learn's *preprocessing.LabelEncoder*.

https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html
"""

# TODO: convert the data from str to integer numbers
# you can use your own method to process, e.g. the LabelEncoder function introduced in the lecture
# target result is stated in below cell
from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

# Solution 1:
data_vec = data.copy(deep=True) # create a deep copy of `data` so that modification of `data_vec` will not change `data`.
for k in data_vec.keys():
  if(type(data_vec[k][0])==str):
    data_vec[k] = encoder.fit_transform(data_vec[k])

# Solution 2:
# See reference:
# Pandas.DataFrame.apply: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html
# Python lambda function: https://www.w3schools.com/python/python_lambda.asp
data_vec = data.apply(lambda col: encoder.fit_transform(col)
           if isinstance(col.iloc[0], str)
           else col)
data_vec

"""## Task 1.2: Split the Vector Representation and Target Label
The dataframe can now be converted into a NumPy array. Then, we will need to split the data into the vector representation X that doesn't contain the target goal and the target ground truth y **<font color="green">(a TODO here)</font>**.
"""

# vector represntation X in shape (32561, 14)
# ground truth y in shape (32561,)
# TODO: assign X and y

# Solution 1: (numpy array slicing)
vectors = data_vec.to_numpy()
X = vectors[:,:-1]
y = vectors[:,-1]

# Solution 2: (column deletion and selection with pandas dataframe)
#X = data_vec.drop(columns=['>50k']).to_numpy() # drop(inplace=False) will create a new dataframe without changing the original data.
print('X.shape:', X.shape)
#y = data_vec.loc[:, '>50k'].to_numpy() # loc() can perform selection by name.
print('y.shape:', y.shape)

"""## Task 1.3: Standardization

Standardization will be performed on X to prevent attributes with large values like fnlwgt from dominating the prediction **<font color="green">(a TODO here)</font>**.

Hint: We can evaluate the sample mean as $\mu_x=\frac 1n \sum_{i=1}^n{x_i}$, and

the sample standard deviation as $\sigma_x=\sqrt{{\sum_{i=1}^n (x_i-\mu_x)^2}/{(n-1)}}$.

Then, we can standardize any feature value $x_i$ as follows:

### $x^{new}_i = \frac{x_i - \mu_x}{\sigma_x}$.

For your self-checking, the mean and sd for the 1st attribute are 38.58164675532078 and 13.640432553581341.

## Split Training and Testing Set
The vectorized data will then be split into a training and testing set for further processing.

In the code below, we show you how to use scikit-learn's *train_test_split()* method to randomly assign the samples to the test or train set.
"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
# test_size: data is split into train and test set in ratio of 8:2
# random_state: this control the shuffle applied to the data before applying the split,
# in order to do the final checking, a fix value of 3 is passed here to make the output reproducible.

"""# Task 2: KNN Classifier
Next, we model the data using KNN and predict y_pred using the X_test data using K=5. **<font color="green">(a TODO here)</font>**

Hint: You may use scikit-learn's *neighbors.KneighborsClassifier*, or do it from scratch.

https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html
"""

# TODO: KNN classification
import numpy as np
# Import additional libraries/modules here.
from scipy.stats import mode
from sklearn.neighbors import KNeighborsClassifier

def knn_classify_sklearn(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray, n_neighbors=5) -> np.ndarray:
    '''
    X_train: numpy array of shape (N, d), where N is the number of training samples, d is the number of features.

    y_train: numpy array of shape (N, ).

    X_test: numpy array of shape (M, d), where M is the number of testing samples, d is the number of features.

    Returns: numpy array of shape (M, ) that predicts the labels of X_test based on KNN.

    Here are some useful functions of scikit-learn classifiers for your reference: fit(), fit_transform(), predict().
    '''
    model = KNeighborsClassifier(n_neighbors=n_neighbors)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    return y_pred


y_pred = knn_classify_sklearn(X_train, y_train, X_test)
'''
is_diff = not np.allclose(y_pred, knn_classify_scratch(X_train, y_train, X_test))
print(f"Your implementation of KNN from scratch is {'in'*is_diff}correct!")
print("Prediction result of scikit-learn classifier:")'''
y_pred

"""## Evaluation Metrics
The performance of the KNN classifier can be evaluated using the F1 metric:

>$ \text{F1 score} = \frac{2}{1/recall+1/precision} = 2 â‹… \frac{recall \cdot precision}{recall + precision}$

<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png width="400"> </img>

While,
>$Accuracy = \frac{\text{True Positive}+\text{True Negative}}{(\text{True Positive}+\text{True Negative}+\text{False Positive}+\text{False Negative})}$

The accuracy doesn't consider the data distribution, so when there are imbalanced classes, we may still get a high accuracy score even though the model makes a poor prediction on one class. So, the F1 metric is more commonly used to prevent this issue.

You can refer to this Supplementary Note on evaluation metrics (https://course.cse.ust.hk/comp2211/notes/supp-model-evaluation-full.pdf), which includes the definition of True Positive, True Negative, False Positive, and False Negative.

You can check out https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9 for further explanation and an example illustration.

## Imbalanced Class Distribution
Our dataset is also an example of an imbalanced class distribution.
"""

# value_counts: it counts the occurance of unique values
data['Level'].value_counts()

# confusion_matrix: return array containing [[True Negative, False Positive],
#                                            [False Negative, True Positive]]
import matplotlib.pyplot as plt
from sklearn import metrics
cm = metrics.confusion_matrix(y_test, y_pred)
disp = metrics.ConfusionMatrixDisplay(cm)
disp.plot()
plt.show()

metrics.accuracy_score(y_test, y_pred)

"""# Unmount Google Drive"""

drive.flush_and_unmount()